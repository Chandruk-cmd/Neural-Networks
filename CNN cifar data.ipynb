{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data:\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "shape of test data:\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes =10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /=255\n",
    "x_test /=255\n",
    "print(\"shape of training data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"shape of test data:\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten , Dense, Activation,Dropout\n",
    "from keras.layers.advanced_activations import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 70)        31570     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 70)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 70)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               2240500   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 2,411,830\n",
      "Trainable params: 2,411,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating the model\n",
    "#building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#convolution layer 1\n",
    "model.add(Conv2D(25, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu', input_shape=(32,32,3)))\n",
    "\n",
    "#convolution layer 2\n",
    "model.add(Conv2D(50, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu' ))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(70, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu' ))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "\n",
    "#hidden layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model    \n",
    "#categorical_crossentropy ( cce ) uses a one-hot array to calculate the probability \n",
    "#adam - combination of both RMS and SGD\n",
    "model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.2277 - accuracy: 0.9291 - val_loss: 0.8113 - val_accuracy: 0.7774\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.2262 - accuracy: 0.9310 - val_loss: 0.7830 - val_accuracy: 0.7753\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2269 - accuracy: 0.9291 - val_loss: 0.7767 - val_accuracy: 0.7827\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2348 - accuracy: 0.9286 - val_loss: 0.7833 - val_accuracy: 0.7795\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2277 - accuracy: 0.9293 - val_loss: 0.7501 - val_accuracy: 0.7817\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2241 - accuracy: 0.9299 - val_loss: 0.7755 - val_accuracy: 0.7795\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2273 - accuracy: 0.9305 - val_loss: 0.7592 - val_accuracy: 0.7824\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2224 - accuracy: 0.9314 - val_loss: 0.7901 - val_accuracy: 0.7846\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2269 - accuracy: 0.9311 - val_loss: 0.8059 - val_accuracy: 0.7805\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2210 - accuracy: 0.9312 - val_loss: 0.7790 - val_accuracy: 0.7858\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2262 - accuracy: 0.9309 - val_loss: 0.8069 - val_accuracy: 0.7817\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2180 - accuracy: 0.9328 - val_loss: 0.7638 - val_accuracy: 0.7816\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2262 - accuracy: 0.9295 - val_loss: 0.7560 - val_accuracy: 0.7866\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2203 - accuracy: 0.9335 - val_loss: 0.8217 - val_accuracy: 0.7758\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2161 - accuracy: 0.9347 - val_loss: 0.8076 - val_accuracy: 0.7835\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2136 - accuracy: 0.9340 - val_loss: 0.8180 - val_accuracy: 0.7805\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2200 - accuracy: 0.9330 - val_loss: 0.7520 - val_accuracy: 0.7869\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2156 - accuracy: 0.9334 - val_loss: 0.8118 - val_accuracy: 0.7840\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2181 - accuracy: 0.9341 - val_loss: 0.8270 - val_accuracy: 0.7721\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2161 - accuracy: 0.9338 - val_loss: 0.7978 - val_accuracy: 0.7786\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2179 - accuracy: 0.9338 - val_loss: 0.7935 - val_accuracy: 0.7830\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2211 - accuracy: 0.9325 - val_loss: 0.7554 - val_accuracy: 0.7810\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2171 - accuracy: 0.9338 - val_loss: 0.7740 - val_accuracy: 0.7790\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2195 - accuracy: 0.9344 - val_loss: 0.7572 - val_accuracy: 0.7760\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2084 - accuracy: 0.9364 - val_loss: 0.7964 - val_accuracy: 0.7759\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2180 - accuracy: 0.9341 - val_loss: 0.8189 - val_accuracy: 0.7830\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2127 - accuracy: 0.9334 - val_loss: 0.7628 - val_accuracy: 0.7814\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2222 - accuracy: 0.9343 - val_loss: 0.7888 - val_accuracy: 0.7822\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2219 - accuracy: 0.9343 - val_loss: 0.7842 - val_accuracy: 0.7789\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2207 - accuracy: 0.9315 - val_loss: 0.7738 - val_accuracy: 0.7836\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2126 - accuracy: 0.9357 - val_loss: 0.7726 - val_accuracy: 0.7858\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2123 - accuracy: 0.9347 - val_loss: 0.7592 - val_accuracy: 0.7790\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2057 - accuracy: 0.9389 - val_loss: 0.8213 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2186 - accuracy: 0.9347 - val_loss: 0.7657 - val_accuracy: 0.7849\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2071 - accuracy: 0.9378 - val_loss: 0.8008 - val_accuracy: 0.7787\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2133 - accuracy: 0.9361 - val_loss: 0.7818 - val_accuracy: 0.7811\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2236 - accuracy: 0.9334 - val_loss: 0.7760 - val_accuracy: 0.7820\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2134 - accuracy: 0.9359 - val_loss: 0.7586 - val_accuracy: 0.7905\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2075 - accuracy: 0.9375 - val_loss: 0.7897 - val_accuracy: 0.7851\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2150 - accuracy: 0.9361 - val_loss: 0.8019 - val_accuracy: 0.7807\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2066 - accuracy: 0.9385 - val_loss: 0.7805 - val_accuracy: 0.7813\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2093 - accuracy: 0.9377 - val_loss: 0.8105 - val_accuracy: 0.7830\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2145 - accuracy: 0.9355 - val_loss: 0.8039 - val_accuracy: 0.7808\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2079 - accuracy: 0.9375 - val_loss: 0.7975 - val_accuracy: 0.7845\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2030 - accuracy: 0.9399 - val_loss: 0.7928 - val_accuracy: 0.7781\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2128 - accuracy: 0.9351 - val_loss: 0.7791 - val_accuracy: 0.7839\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2088 - accuracy: 0.9371 - val_loss: 0.8148 - val_accuracy: 0.7818\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2094 - accuracy: 0.9372 - val_loss: 0.8094 - val_accuracy: 0.7807\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2020 - accuracy: 0.9391 - val_loss: 0.8398 - val_accuracy: 0.7831\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2068 - accuracy: 0.9387 - val_loss: 0.7918 - val_accuracy: 0.7830\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2046 - accuracy: 0.9395 - val_loss: 0.8359 - val_accuracy: 0.7809\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2071 - accuracy: 0.9365 - val_loss: 0.8305 - val_accuracy: 0.7823\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2029 - accuracy: 0.9393 - val_loss: 0.8138 - val_accuracy: 0.7804\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2105 - accuracy: 0.9373 - val_loss: 0.8316 - val_accuracy: 0.7837\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2041 - accuracy: 0.9399 - val_loss: 0.8149 - val_accuracy: 0.7762\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2081 - accuracy: 0.9373 - val_loss: 0.8344 - val_accuracy: 0.7832\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2055 - accuracy: 0.9381 - val_loss: 0.7938 - val_accuracy: 0.7775\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2117 - accuracy: 0.9372 - val_loss: 0.8092 - val_accuracy: 0.7866\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2066 - accuracy: 0.9395 - val_loss: 0.8308 - val_accuracy: 0.7784\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2057 - accuracy: 0.9397 - val_loss: 0.8488 - val_accuracy: 0.7781\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2010 - accuracy: 0.9411 - val_loss: 0.8207 - val_accuracy: 0.7802\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2075 - accuracy: 0.9387 - val_loss: 0.7991 - val_accuracy: 0.7849\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2044 - accuracy: 0.9393 - val_loss: 0.8285 - val_accuracy: 0.7782\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2105 - accuracy: 0.9370 - val_loss: 0.8085 - val_accuracy: 0.7836\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1991 - accuracy: 0.9398 - val_loss: 0.8233 - val_accuracy: 0.7790\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1992 - accuracy: 0.9420 - val_loss: 0.8267 - val_accuracy: 0.7843\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2067 - accuracy: 0.9379 - val_loss: 0.8725 - val_accuracy: 0.7784\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1998 - accuracy: 0.9401 - val_loss: 0.8221 - val_accuracy: 0.7788\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1961 - accuracy: 0.9411 - val_loss: 0.7980 - val_accuracy: 0.7847\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2048 - accuracy: 0.9399 - val_loss: 0.8189 - val_accuracy: 0.7800\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1961 - accuracy: 0.9412 - val_loss: 0.8409 - val_accuracy: 0.7852\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2020 - accuracy: 0.9407 - val_loss: 0.8409 - val_accuracy: 0.7788\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2044 - accuracy: 0.9402 - val_loss: 0.8094 - val_accuracy: 0.7856\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1993 - accuracy: 0.9406 - val_loss: 0.8047 - val_accuracy: 0.7828\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1972 - accuracy: 0.9414 - val_loss: 0.8094 - val_accuracy: 0.7847\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1994 - accuracy: 0.9409 - val_loss: 0.7731 - val_accuracy: 0.7845\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1914 - accuracy: 0.9425 - val_loss: 0.8505 - val_accuracy: 0.7813\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1989 - accuracy: 0.9409 - val_loss: 0.8277 - val_accuracy: 0.7836\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1954 - accuracy: 0.9419 - val_loss: 0.8543 - val_accuracy: 0.7826\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1940 - accuracy: 0.9439 - val_loss: 0.8294 - val_accuracy: 0.7891\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2037 - accuracy: 0.9396 - val_loss: 0.7891 - val_accuracy: 0.7842\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1966 - accuracy: 0.9415 - val_loss: 0.8530 - val_accuracy: 0.7859\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2025 - accuracy: 0.9401 - val_loss: 0.7801 - val_accuracy: 0.7866\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2022 - accuracy: 0.9402 - val_loss: 0.7730 - val_accuracy: 0.7891\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1902 - accuracy: 0.9442 - val_loss: 0.8035 - val_accuracy: 0.7913\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2008 - accuracy: 0.9412 - val_loss: 0.8337 - val_accuracy: 0.7854\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1898 - accuracy: 0.9433 - val_loss: 0.8731 - val_accuracy: 0.7817\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1930 - accuracy: 0.9441 - val_loss: 0.8085 - val_accuracy: 0.7890\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1988 - accuracy: 0.9419 - val_loss: 0.8390 - val_accuracy: 0.7858\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2045 - accuracy: 0.9405 - val_loss: 0.8319 - val_accuracy: 0.7779\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2021 - accuracy: 0.9412 - val_loss: 0.8081 - val_accuracy: 0.7809\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1955 - accuracy: 0.9429 - val_loss: 0.8353 - val_accuracy: 0.7850\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1922 - accuracy: 0.9432 - val_loss: 0.8202 - val_accuracy: 0.7871\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1876 - accuracy: 0.9447 - val_loss: 0.8477 - val_accuracy: 0.7878\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1937 - accuracy: 0.9438 - val_loss: 0.8214 - val_accuracy: 0.7890\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1979 - accuracy: 0.9425 - val_loss: 0.8524 - val_accuracy: 0.7853\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1874 - accuracy: 0.9451 - val_loss: 0.8876 - val_accuracy: 0.7849\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1982 - accuracy: 0.9418 - val_loss: 0.8212 - val_accuracy: 0.7808\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1952 - accuracy: 0.9423 - val_loss: 0.8259 - val_accuracy: 0.7833\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1939 - accuracy: 0.9428 - val_loss: 0.8305 - val_accuracy: 0.7880\n",
      "Accuracy: 78.80%\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=32) \n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(x_test, y_test, verbose=0) \n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create an HDF5 file with the name ‘project_model’  and extension ‘.h5’. Hierarchical Data Format (HDF) \n",
    "from keras.models import load_model \n",
    "model.save('project_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the saved model \n",
    "from keras.models import load_model \n",
    "model = load_model('project_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.preprocessing import image\n",
    "# Give the link of the image here to test \n",
    "test_image1 =image.load_img('C://Users//WoU_AI_ML//Documents//4.jfif',target_size =(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Horse\n"
     ]
    }
   ],
   "source": [
    "test_image =image.img_to_array(test_image1) \n",
    "test_image =np.expand_dims(test_image, axis =0) \n",
    "result = model.predict(test_image) \n",
    "print(result) \n",
    "if result[0][0]==1: \n",
    "    print(\"Aeroplane\") \n",
    "elif result[0][1]==1: \n",
    "    print('Automobile') \n",
    "elif result[0][2]==1: \n",
    "    print('Bird') \n",
    "elif result[0][3]==1: \n",
    "    print('Cat') \n",
    "elif result[0][4]==1: \n",
    "    print('Deer') \n",
    "elif result[0][5]==1: \n",
    "    print('Dog') \n",
    "elif result[0][6]==1: \n",
    "    print('Frog') \n",
    "elif result[0][7]==1: \n",
    "    print('Horse') \n",
    "elif result[0][8]==1: \n",
    "    print('Ship') \n",
    "elif result[0][9]==1: \n",
    "    print('Truck') \n",
    "else: \n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1813897ab20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(test_image1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
